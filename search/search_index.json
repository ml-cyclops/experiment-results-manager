{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\udd2c ERM: Experiment Results Manager","text":"<p>Light-weight alternative to <code>mlflow</code> experiment tracking that doesn't require kubernetes. Useful tool to compare metrics between training attempts in your model training workflow</p>"},{"location":"#features","title":"\u2728 Features","text":"<ul> <li>\ud83d\udcc8 Track plots, metrics, &amp; other data</li> <li>\ud83d\udc40 Side-by-side comparison </li> <li>\ud83d\udcbe Experiment registry </li> <li>\u26c5\ufe0f Supports S3, GCS, Azure and others (via <code>fsspec</code>)</li> </ul>"},{"location":"#examples-demos","title":"\ud83d\ude80 Examples &amp; Demos","text":"<ul> <li>Quick and easy: serialize_and_deserialize.ipynb</li> <li>Practical but more involved: compare_runs.ipynb</li> <li>Browse the registry: browse_registry.ipynb</li> </ul>"},{"location":"#get-started","title":"\u2705 Get Started","text":""},{"location":"#installation","title":"Installation","text":"<pre><code>pip install experiment-results-manager \\\ngcsfs \\\ns3fs\n# install s3fs if you plan to store data in s3\n# install gcsfs if you plan to store data in google cloud storage\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<pre><code>import experiment_results_manager as erm\n# Create an experiment run\ner = erm.ExperimentRun(\nexperiment_id=\"my_experiment\",\nvariant_id=\"main\"\n)\n# Log relevant data\ner.log_param(\"objective\", \"rmse\")\ner.log_metric(\"rmse\", \"0.9\")\ner.log_figure(mpl_fig, \"ROC Curve\")\ner.log_text(\"lorem ipsum...\", \"text\")\n# Display the report (if you are in a notebook)\nhtml = erm.compare_runs(er)\ndisplay(HTML(html))\n# Save to registry\nsaved_path = erm.save_run_to_registry(er, \"s3://erm-registry\")\n</code></pre> <p> Made with \u2764\ufe0f in Berlin </p>"},{"location":"api_reference/","title":"\ud83d\udc69\u200d\ud83d\udcbb API Reference","text":""},{"location":"api_reference/#experiment_results_manager","title":"experiment_results_manager","text":""},{"location":"api_reference/#experiment_results_manager.ExperimentRun","title":"ExperimentRun","text":"<p>Example usage: <pre><code>import experiment_results_manager as erm\n# Create an experiment run\ner = erm.ExperimentRun(\nexperiment_id=\"my_experiment\",\nvariant_id=\"main\"\n)\n# Log relevant data\ner.log_param(\"objective\", \"rmse\")\ner.log_metric(\"rmse\", \"0.9\")\ner.log_figure(mpl_fig, \"ROC Curve\")\ner.log_text(\"lorem ipsum...\", \"text\")\ner.log_artifact(\npickle.dumps(model),\nartifact_id=\"model\",\nfilename=\"model.pickle\"\n)\n# Display the run\nhtml = erm.compare_runs(er)\n# Or compare side by side with other runs\nhtml = erm.compare_runs(er, er2, er3)\ndisplay(HTML(html))\n# Save the run to access later\nsaved_path = erm.save_run_to_registry(er, \"s3://erm-registry\")\n</code></pre></p>"},{"location":"api_reference/#experiment_results_manager.experiment_run.ExperimentRun.__init__","title":"__init__","text":"<pre><code>__init__(\nexperiment_id: str,\nvariant_id: str = \"main\",\nrun_id: Optional[str] = None,\ntimestamp_utc: Optional[datetime] = None,\nfeatures: Optional[List[str]] = None,\nparams: Optional[\nDict[str, Union[str, int, float]]\n] = None,\nmetrics: Optional[\nDict[str, Union[str, int, float]]\n] = None,\ndicts: Optional[Dict[str, Dict[str, Any]]] = None,\nartifacts: Optional[Dict[str, Artifact]] = None,\n) -&gt; None\n</code></pre> <p>Initializes a new <code>ExperimentRun</code> object with the given experiment_id, <code>variant_id</code>, <code>run_id</code>, and <code>timestamp_utc</code>. If <code>timestamp_utc</code> is not provided, it defaults to the current UTC datetime. If <code>run_id</code> is not provided, it is generated from the <code>timestamp_utc</code> using the format \"%Y_%m_%d__%H_%M_%S\".</p>"},{"location":"api_reference/#experiment_results_manager.experiment_run.ExperimentRun.log_artifact","title":"log_artifact","text":"<pre><code>log_artifact(\nsrc_path_or_bytes: Union[str, bytes],\nartifact_id: str,\nfilename: Union[str, None] = None,\nartifact_type: ArtifactType = ArtifactType.BINARY,\n) -&gt; None\n</code></pre> <p>Logs an artifact to the experiment run. :param str|bytes src_path_or_bytes: The path or byte array to the artifact. :param str artifact_id: The id of the artifact. :param str|None filename: The run-relative filename of the artifact. :param ArtifactType artifact_type: The type of the artifact.</p>"},{"location":"api_reference/#experiment_results_manager.experiment_run.ExperimentRun.log_dict","title":"log_dict","text":"<pre><code>log_dict(\ndict_name: str,\ndata: Dict[str, Union[str, int, float, Any]],\n) -&gt; None\n</code></pre> <p>Logs a dictionary of <code>data</code> with the given <code>dict_name</code>.</p>"},{"location":"api_reference/#experiment_results_manager.experiment_run.ExperimentRun.log_figure","title":"log_figure","text":"<pre><code>log_figure(\nfig: Union[\nplotly.graph_objs.Figure,\nmatplotlib.figure.Figure,\nmatplotlib.axes.Axes,\n],\nartifact_id: str,\n) -&gt; None\n</code></pre> <p>Logs a figure to the experiment run.</p>"},{"location":"api_reference/#experiment_results_manager.experiment_run.ExperimentRun.log_image","title":"log_image","text":"<pre><code>log_image(\nsrc_path_or_bytes: Union[str, bytes],\nartifact_id: str,\nfilename: Optional[str] = None,\n) -&gt; None\n</code></pre> <p>Logs an image with the given artifact_id and either the path to the image file (src_path_or_bytes is a string) or the contents of the image file (src_path_or_bytes is bytes). If a filename is not provided, the artifact_id is used as the filename. The image is stored as a PNG artifact in the artifacts dictionary of the ExperimentRun object.</p>"},{"location":"api_reference/#experiment_results_manager.experiment_run.ExperimentRun.log_metric","title":"log_metric","text":"<pre><code>log_metric(key: str, value: Union[str, int, float]) -&gt; None\n</code></pre> <p>Logs a metric to the experiment run.</p>"},{"location":"api_reference/#experiment_results_manager.experiment_run.ExperimentRun.log_metrics","title":"log_metrics","text":"<pre><code>log_metrics(\ndata: Dict[str, Union[str, int, float]]\n) -&gt; None\n</code></pre> <p>Appends <code>data</code> to the <code>metrics</code> dict.</p>"},{"location":"api_reference/#experiment_results_manager.experiment_run.ExperimentRun.log_param","title":"log_param","text":"<pre><code>log_param(key: str, value: Union[str, int, float]) -&gt; None\n</code></pre> <p>Logs a parameter to the experiment run.</p>"},{"location":"api_reference/#experiment_results_manager.experiment_run.ExperimentRun.log_params","title":"log_params","text":"<pre><code>log_params(data: Dict[str, Union[str, int, float]]) -&gt; None\n</code></pre> <p>Appends <code>data</code> to the <code>params</code> dict.</p>"},{"location":"api_reference/#experiment_results_manager.experiment_run.ExperimentRun.log_text","title":"log_text","text":"<pre><code>log_text(text: Union[str, bytes], artifact_id: str) -&gt; None\n</code></pre> <p>Logs <code>text</code> with the given <code>artifact_id</code> and <code>text</code> (<code>str</code> or <code>bytes</code> that represent utf-8). The text is stored as a binary artifact in the ExperimentRun.</p>"},{"location":"api_reference/#experiment_results_manager.list_experiments","title":"list_experiments","text":"<pre><code>list_experiments(\nregistry_uri: str,\nfs: Optional[AbstractFileSystem] = None,\n) -&gt; List[str]\n</code></pre> <p>List experiments in the given registry.</p> <p>Parameters:</p> Name Type Description Default <code>registry_uri</code> <code>str</code> <p>The URI of the registry to list experiments for.</p> required <code>fs</code> <code>Optional[fsspec.AbstractFileSystem]</code> <p>The filesystem to use to access the registry, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of experiment names.</p>"},{"location":"api_reference/#experiment_results_manager.list_runs","title":"list_runs","text":"<pre><code>list_runs(\nregistry_uri: str,\nexperiment_id: str,\nvariant_id: str,\nfs: Optional[AbstractFileSystem] = None,\n) -&gt; List[str]\n</code></pre> <p>List the runs for the given experiment and variant.</p> <p>Parameters:</p> Name Type Description Default <code>registry_uri</code> <code>str</code> <p>The URI of the registry where the experiment is stored.</p> required <code>experiment_id</code> <code>str</code> <p>The ID of the experiment.</p> required <code>variant_id</code> <code>str</code> <p>The ID of the variant.</p> required <code>fs</code> <code>Optional[fsspec.AbstractFileSystem]</code> <p>The filesystem to use. If None, a new filesystem will be created using fsspec. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of strings representing the runs for the given experiment and variant.</p>"},{"location":"api_reference/#experiment_results_manager.list_variants","title":"list_variants","text":"<pre><code>list_variants(\nregistry_uri: str,\nexperiment_id: str,\nfs: Optional[AbstractFileSystem] = None,\n) -&gt; List[str]\n</code></pre> <p>List the variants available for an experiment in the given registry URI and     experiment ID.</p> <p>Parameters:</p> Name Type Description Default <code>registry_uri</code> <code>str</code> <p>The URI of the registry to list the variants from.</p> required <code>experiment_id</code> <code>str</code> <p>The ID of the experiment to list the variants from.</p> required <code>fs</code> <code>Optional[fsspec.AbstractFileSystem]</code> <p>The filesystem to use to access the registry. If None, a new one will be created for the given experiment ID. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of variant names stored for the experiment.</p>"},{"location":"api_reference/#experiment_results_manager.load_run_from_path","title":"load_run_from_path","text":"<pre><code>load_run_from_path(run_path: str) -&gt; ExperimentRun\n</code></pre> <p>Load an ExperimentRun object from a given path.</p> <p>Parameters:</p> Name Type Description Default <code>run_path</code> <code>str</code> <p>The path to the ExperimentRun directory.</p> required <p>Returns:</p> Name Type Description <code>ExperimentRun</code> <code>ExperimentRun</code> <p>An ExperimentRun object populated with data from the given path.</p>"},{"location":"api_reference/#experiment_results_manager.load_run_from_registry","title":"load_run_from_registry","text":"<pre><code>load_run_from_registry(\nexperiment_registry_path: str,\nexperiment_id: str,\nvariant_id: str = \"main\",\nrun_id: Optional[str] = None,\n) -&gt; ExperimentRun\n</code></pre> <p>Load an experiment run from its registry path.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_registry_path</code> <code>str</code> <p>The root path of the experiment registry.</p> required <code>experiment_id</code> <code>str</code> <p>The ID of the experiment.</p> required <code>variant_id</code> <code>str</code> <p>The ID of the variant. Defaults to \"main\".</p> <code>'main'</code> <code>run_id</code> <code>str</code> <p>The ID of the run. If not provided, the latest run for the variant is used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ExperimentRun</code> <code>ExperimentRun</code> <p>The loaded experiment run.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the experiment or variant ID is invalid.</p> <code>FileNotFoundError</code> <p>If the run path does not exist.</p>"},{"location":"api_reference/#experiment_results_manager.save_run_to_path","title":"save_run_to_path","text":"<pre><code>save_run_to_path(\ner: ExperimentRun,\npath: str,\nfs: Optional[fsspec.AbstractFileSystem] = None,\noverwrite: bool = False,\n) -&gt; None\n</code></pre> <p>Save an experiment run to a file system path.</p> <p>Parameters:</p> Name Type Description Default <code>er</code> <code>ExperimentRun</code> <p>The experiment run to save.</p> required <code>path</code> <code>str</code> <p>The path to save the experiment run to.</p> required <code>fs</code> <code>Optional[fsspec.AbstractFileSystem]</code> <p>The file system to use. Defaults to None.</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite an existing experiment run at the same path. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If a run already exists at the given path and <code>overwrite</code> is set to False.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"api_reference/#experiment_results_manager.save_run_to_registry","title":"save_run_to_registry","text":"<pre><code>save_run_to_registry(\ner: ExperimentRun,\nexperiment_registry_path: str,\nfs: Optional[fsspec.AbstractFileSystem] = None,\noverwrite: bool = False,\n) -&gt; str\n</code></pre> <p>Saves an ExperimentRun object to a registry on a file system.</p> <p>Parameters:</p> Name Type Description Default <code>er</code> <code>ExperimentRun</code> <p>The ExperimentRun object to save.</p> required <code>experiment_registry_path</code> <code>str</code> <p>The path to the experiment registry directory.</p> required <code>fs</code> <code>Optional[fsspec.AbstractFileSystem]</code> <p>The file system to use. If None, get_fs_from_uri(experiment_registry_path) is used.</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite an existing run with the same ID. If False and a run with the same ID exists, a ValueError is raised.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The path to the saved run.</p>"}]}